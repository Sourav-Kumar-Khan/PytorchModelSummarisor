{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "\n",
        "def generate_random_network():\n",
        "    layers = []\n",
        "    input_channels = random.randint(1, 3)\n",
        "    input_size = random.randint(32, 224)\n",
        "    output_size = random.randint(1, 10)\n",
        "    num_layers = random.randint(2, 5)\n",
        "\n",
        "    current_channels = input_channels\n",
        "    current_size = input_size\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        # Randomly choose layer type\n",
        "        layer_type = random.choice(['linear', 'conv1d', 'conv2d'] if i < num_layers - 1 else ['linear'])\n",
        "\n",
        "        if layer_type == 'linear':\n",
        "            if i == 0:\n",
        "                in_features = current_channels * current_size * current_size\n",
        "            else:\n",
        "                in_features = get_output_features(layers[-1], current_channels, current_size)\n",
        "            out_features = random.randint(10, 200) if i < num_layers - 1 else output_size\n",
        "            layers.append(nn.Linear(in_features, out_features))\n",
        "            current_channels = 1\n",
        "            current_size = out_features\n",
        "        elif layer_type == 'conv1d':\n",
        "            out_channels = random.randint(16, 64)\n",
        "            layers.append(nn.Conv1d(current_channels, out_channels, kernel_size=3, padding=1))\n",
        "            current_channels = out_channels\n",
        "        elif layer_type == 'conv2d':\n",
        "            out_channels = random.randint(16, 64)\n",
        "            layers.append(nn.Conv2d(current_channels, out_channels, kernel_size=3, padding=1))\n",
        "            current_channels = out_channels\n",
        "\n",
        "        # Randomly add normalization\n",
        "        if random.choice([True, False]):\n",
        "            if layer_type == 'linear':\n",
        "                layers.append(nn.BatchNorm1d(out_features))\n",
        "            elif layer_type == 'conv1d':\n",
        "                layers.append(nn.BatchNorm1d(out_channels))\n",
        "            elif layer_type == 'conv2d':\n",
        "                layers.append(nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        # Randomly add activation functions\n",
        "        if random.choice([True, False]):\n",
        "            layers.append(random.choice([nn.ReLU(), nn.LeakyReLU(), nn.Tanh(), nn.Sigmoid()]))\n",
        "\n",
        "        # Randomly add dropout\n",
        "        if random.choice([True, False]):\n",
        "            layers.append(nn.Dropout(p=random.uniform(0.1, 0.5)))\n",
        "\n",
        "    # Ensure the last layer is Linear and outputs the correct size\n",
        "    if not isinstance(layers[-1], nn.Linear) or layers[-1].out_features != output_size:\n",
        "        in_features = get_output_features(layers[-1], current_channels, current_size)\n",
        "        layers.append(nn.Linear(in_features, output_size))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def get_output_features(layer, current_channels, current_size):\n",
        "    if isinstance(layer, nn.Linear):\n",
        "        return layer.out_features\n",
        "    elif isinstance(layer, (nn.Conv1d, nn.Conv2d)):\n",
        "        return layer.out_channels\n",
        "    elif isinstance(layer, (nn.BatchNorm1d, nn.BatchNorm2d)):\n",
        "        return layer.num_features\n",
        "    elif isinstance(layer, (nn.ReLU, nn.LeakyReLU, nn.Tanh, nn.Sigmoid, nn.Dropout)):\n",
        "        return current_channels * current_size * current_size\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported layer type: {type(layer)}\")\n",
        "\n",
        "# Test the function\n",
        "try:\n",
        "    model = generate_random_network()\n",
        "    print(model)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5uB0ilxyaux",
        "outputId": "4b5f9b8c-a035-4071-afa9-f5111ceebbed"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv1d(3, 28, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "  (1): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): Conv1d(28, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "  (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (4): Dropout(p=0.32361621662810897, inplace=False)\n",
            "  (5): Linear(in_features=446224, out_features=7, bias=True)\n",
            "  (6): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): Linear(in_features=7, out_features=7, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_description(model):\n",
        "    layers = list(model.children())\n",
        "\n",
        "    # Determine input shape\n",
        "    first_layer = layers[0]\n",
        "    if isinstance(first_layer, nn.Linear):\n",
        "        input_shape = f\"b,{first_layer.in_features}\"\n",
        "    elif isinstance(first_layer, nn.Conv1d):\n",
        "        input_shape = f\"b,{first_layer.in_channels},w\"\n",
        "    elif isinstance(first_layer, nn.Conv2d):\n",
        "        input_shape = f\"b,{first_layer.in_channels},h,w\"\n",
        "    else:\n",
        "        input_shape = \"unknown\"\n",
        "\n",
        "    # Determine output shape\n",
        "    last_layer = next((layer for layer in reversed(layers) if isinstance(layer, nn.Linear)), None)\n",
        "    if last_layer:\n",
        "        output_shape = f\"b,{last_layer.out_features}\"\n",
        "    else:\n",
        "        output_shape = \"unknown\"\n",
        "\n",
        "    description = f\"This neural network takes an input of shape ({input_shape}) \"\n",
        "    description += f\"and produces an output of shape ({output_shape}). \"\n",
        "    description += f\"It consists of {len(layers)} layers, including \"\n",
        "\n",
        "    layer_descriptions = []\n",
        "    for layer in layers:\n",
        "        if isinstance(layer, nn.Linear):\n",
        "            layer_descriptions.append(f\"a Linear layer ({layer.in_features} -> {layer.out_features})\")\n",
        "        elif isinstance(layer, nn.Conv1d):\n",
        "            layer_descriptions.append(f\"a 1D Convolutional layer ({layer.in_channels} -> {layer.out_channels}, kernel_size={layer.kernel_size[0]})\")\n",
        "        elif isinstance(layer, nn.Conv2d):\n",
        "            layer_descriptions.append(f\"a 2D Convolutional layer ({layer.in_channels} -> {layer.out_channels}, kernel_size={layer.kernel_size})\")\n",
        "        elif isinstance(layer, nn.BatchNorm1d):\n",
        "            layer_descriptions.append(f\"a 1D Batch Normalization (num_features={layer.num_features})\")\n",
        "        elif isinstance(layer, nn.BatchNorm2d):\n",
        "            layer_descriptions.append(f\"a 2D Batch Normalization (num_features={layer.num_features})\")\n",
        "        elif isinstance(layer, nn.ReLU):\n",
        "            layer_descriptions.append(\"a ReLU activation\")\n",
        "        elif isinstance(layer, nn.LeakyReLU):\n",
        "            layer_descriptions.append(f\"a Leaky ReLU activation (negative_slope={layer.negative_slope:.2f})\")\n",
        "        elif isinstance(layer, nn.Tanh):\n",
        "            layer_descriptions.append(\"a Tanh activation\")\n",
        "        elif isinstance(layer, nn.Sigmoid):\n",
        "            layer_descriptions.append(\"a Sigmoid activation\")\n",
        "        elif isinstance(layer, nn.Dropout):\n",
        "            layer_descriptions.append(f\"a Dropout layer (p={layer.p:.2f})\")\n",
        "        else:\n",
        "            layer_descriptions.append(f\"an unknown layer type: {type(layer).__name__}\")\n",
        "\n",
        "    description += \", \".join(layer_descriptions) + \".\"\n",
        "    return description\n",
        "\n",
        "# Example usage:\n",
        "model = generate_random_network()\n",
        "description = generate_description(model)\n",
        "print(description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQhZ5dOmyeC5",
        "outputId": "12bc4573-e7c2-4876-8cb5-ae3568d1f75e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This neural network takes an input of shape (b,41616) and produces an output of shape (b,8). It consists of 10 layers, including a Linear layer (41616 -> 135), a 1D Batch Normalization (num_features=135), a Sigmoid activation, a Dropout layer (p=0.22), a 2D Convolutional layer (1 -> 21, kernel_size=(3, 3)), a 2D Batch Normalization (num_features=21), a ReLU activation, a 2D Convolutional layer (21 -> 20, kernel_size=(3, 3)), a 2D Batch Normalization (num_features=20), a Linear layer (20 -> 8).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "def generate_dataset(num_samples):\n",
        "    dataset = []\n",
        "    for _ in range(num_samples):\n",
        "        model = generate_random_network()\n",
        "        description = generate_description(model)\n",
        "        dataset.append((str(model), description))\n",
        "        # Explicitly delete variables and run garbage collection\n",
        "        del model\n",
        "        del description\n",
        "        gc.collect()\n",
        "    return dataset\n",
        "\n",
        "# Generate samples dataset\n",
        "# sample_df = generate_dataset(1000)"
      ],
      "metadata": {
        "id": "ory2GcyiyiJS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsUJGpgt55V7",
        "outputId": "8a67eee3-8dd4-4d76-89c5-aeb8f31d537e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Sequential(\\n  (0): Linear(in_features=34225, out_features=191, bias=True)\\n  (1): BatchNorm1d(191, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n  (2): LeakyReLU(negative_slope=0.01)\\n  (3): Linear(in_features=36481, out_features=8, bias=True)\\n  (4): Tanh()\\n  (5): Linear(in_features=64, out_features=8, bias=True)\\n)',\n",
              " 'This neural network takes an input of shape (b,34225) and produces an output of shape (b,8). It consists of 6 layers, including a Linear layer (34225 -> 191), a 1D Batch Normalization (num_features=191), a Leaky ReLU activation (negative_slope=0.01), a Linear layer (36481 -> 8), a Tanh activation, a Linear layer (64 -> 8).')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(sample_df[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1b8uxaR6Rdo",
        "outputId": "d9be1166-4bed-4fa3-cbea-6a9c92be0f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def save_dataset(dataset, filename):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(dataset, f)\n",
        "\n",
        "# save_dataset(sample_df, 'neural_network_dataset.pkl')"
      ],
      "metadata": {
        "id": "_Q4-WNK45kU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukHTSQw0xLhv",
        "outputId": "16e45a24-5346-4f3b-f06d-0fa0f23b58e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 366812\n",
            "drwxr-xr-x 1 root root      4096 Jul 13 10:45 .\n",
            "drwxr-xr-x 1 root root      4096 Jul 13 09:30 ..\n",
            "-rw-r--r-- 1 root root 374524731 Jul 13 11:08 checkpoint.pt\n",
            "drwxr-xr-x 4 root root      4096 Jul 11 13:21 .config\n",
            "drwx------ 5 root root      4096 Jul 13 10:45 drive\n",
            "-rw-r--r-- 1 root root   1061749 Jul 13 11:19 neural_network_dataset.pkl\n",
            "drwxr-xr-x 1 root root      4096 Jul 11 13:22 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DCrSzOxzcqij",
        "outputId": "705b7217-eece-4629-f882-64bda121938c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class TransformerSeq2Seq(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.1):\n",
        "        super(TransformerSeq2Seq, self).__init__()\n",
        "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)\n",
        "        self.fc_out = nn.Linear(d_model, output_dim)\n",
        "        self.src_tok_emb = nn.Embedding(input_dim, d_model)\n",
        "        self.tgt_tok_emb = nn.Embedding(output_dim, d_model)\n",
        "        self.positional_encoding = nn.Embedding(5000, d_model)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_seq_len, N = src.shape\n",
        "        tgt_seq_len, N = tgt.shape\n",
        "\n",
        "        src_positions = (\n",
        "            torch.arange(0, src_seq_len).unsqueeze(1).expand(src_seq_len, N).to(src.device)\n",
        "        )\n",
        "        tgt_positions = (\n",
        "            torch.arange(0, tgt_seq_len).unsqueeze(1).expand(tgt_seq_len, N).to(tgt.device)\n",
        "        )\n",
        "\n",
        "        embed_src = self.src_tok_emb(src) + self.positional_encoding(src_positions)\n",
        "        embed_tgt = self.tgt_tok_emb(tgt) + self.positional_encoding(tgt_positions)\n",
        "\n",
        "        transformer_out = self.transformer(embed_src, embed_tgt)\n",
        "        out = self.fc_out(transformer_out)\n",
        "\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "TPTjF2ptb5v8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Example input and output\n",
        "example_input = \"Sequential((0): Linear(in_features=38809, out_features=26, bias=True) (1): LeakyReLU(negative_slope=0.01) (2): Linear(in_features=676, out_features=183, bias=True) (3): BatchNorm1d(183, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (4): LeakyReLU(negative_slope=0.01) (5): Conv2d(1, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (6): Dropout(p=0.11890518865721189, inplace=False) (7): Linear(in_features=837225, out_features=8, bias=True))\"\n",
        "example_output = \"This neural network takes an input of shape (b,38809) and produces an output of shape (b,8). It consists of 8 layers, including a Linear layer (38809 -> 26), a Leaky ReLU activation (negative_slope=0.01), a Linear layer (676 -> 183), a 1D Batch Normalization (num_features=183), a Leaky ReLU activation (negative_slope=0.01), a 2D Convolutional layer (1 -> 25, kernel_size=(3, 3)), a Dropout layer (p=0.12), a Linear layer (837225 -> 8).\"\n",
        "\n",
        "# Tokenize the input and output\n",
        "input_tokens = tokenizer.tokenize(example_input)\n",
        "output_tokens = tokenizer.tokenize(example_output)\n",
        "\n",
        "print(\"Input Tokens:\", input_tokens)\n",
        "print(\"Output Tokens:\", output_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-1rgVoefXSx",
        "outputId": "89f796e2-9ee6-469a-cb4e-7ca5075d4e80"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Tokens: ['sequential', '(', '(', '0', ')', ':', 'linear', '(', 'in', '_', 'features', '=', '38', '##80', '##9', ',', 'out', '_', 'features', '=', '26', ',', 'bias', '=', 'true', ')', '(', '1', ')', ':', 'leak', '##yre', '##lu', '(', 'negative', '_', 'slope', '=', '0', '.', '01', ')', '(', '2', ')', ':', 'linear', '(', 'in', '_', 'features', '=', '67', '##6', ',', 'out', '_', 'features', '=', '183', ',', 'bias', '=', 'true', ')', '(', '3', ')', ':', 'batch', '##nor', '##m', '##1', '##d', '(', '183', ',', 'eps', '=', '1', '##e', '-', '05', ',', 'momentum', '=', '0', '.', '1', ',', 'af', '##fine', '=', 'true', ',', 'track', '_', 'running', '_', 'stats', '=', 'true', ')', '(', '4', ')', ':', 'leak', '##yre', '##lu', '(', 'negative', '_', 'slope', '=', '0', '.', '01', ')', '(', '5', ')', ':', 'con', '##v', '##2', '##d', '(', '1', ',', '25', ',', 'kernel', '_', 'size', '=', '(', '3', ',', '3', ')', ',', 'stride', '=', '(', '1', ',', '1', ')', ',', 'pad', '##ding', '=', '(', '1', ',', '1', ')', ')', '(', '6', ')', ':', 'drop', '##out', '(', 'p', '=', '0', '.', '118', '##90', '##51', '##8', '##86', '##57', '##21', '##18', '##9', ',', 'in', '##pl', '##ace', '=', 'false', ')', '(', '7', ')', ':', 'linear', '(', 'in', '_', 'features', '=', '83', '##7', '##22', '##5', ',', 'out', '_', 'features', '=', '8', ',', 'bias', '=', 'true', ')', ')']\n",
            "Output Tokens: ['this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b', ',', '38', '##80', '##9', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b', ',', '8', ')', '.', 'it', 'consists', 'of', '8', 'layers', ',', 'including', 'a', 'linear', 'layer', '(', '38', '##80', '##9', '-', '>', '26', ')', ',', 'a', 'leak', '##y', 're', '##lu', 'activation', '(', 'negative', '_', 'slope', '=', '0', '.', '01', ')', ',', 'a', 'linear', 'layer', '(', '67', '##6', '-', '>', '183', ')', ',', 'a', '1', '##d', 'batch', 'normal', '##ization', '(', 'nu', '##m', '_', 'features', '=', '183', ')', ',', 'a', 'leak', '##y', 're', '##lu', 'activation', '(', 'negative', '_', 'slope', '=', '0', '.', '01', ')', ',', 'a', '2d', 'con', '##vo', '##lu', '##tion', '##al', 'layer', '(', '1', '-', '>', '25', ',', 'kernel', '_', 'size', '=', '(', '3', ',', '3', ')', ')', ',', 'a', 'drop', '##out', 'layer', '(', 'p', '=', '0', '.', '12', ')', ',', 'a', 'linear', 'layer', '(', '83', '##7', '##22', '##5', '-', '>', '8', ')', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tokens to input IDs\n",
        "input_ids = tokenizer.convert_tokens_to_ids(input_tokens)\n",
        "output_ids = tokenizer.convert_tokens_to_ids(output_tokens)\n",
        "\n",
        "print(\"Input IDs:\", input_ids)\n",
        "print(\"Output IDs:\", output_ids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ_VCH5DhfmV",
        "outputId": "1f3d1290-258c-4921-c85b-1d855f4592de"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs: [25582, 1006, 1006, 1014, 1007, 1024, 7399, 1006, 1999, 1035, 2838, 1027, 4229, 17914, 2683, 1010, 2041, 1035, 2838, 1027, 2656, 1010, 13827, 1027, 2995, 1007, 1006, 1015, 1007, 1024, 17271, 16363, 7630, 1006, 4997, 1035, 9663, 1027, 1014, 1012, 5890, 1007, 1006, 1016, 1007, 1024, 7399, 1006, 1999, 1035, 2838, 1027, 6163, 2575, 1010, 2041, 1035, 2838, 1027, 18677, 1010, 13827, 1027, 2995, 1007, 1006, 1017, 1007, 1024, 14108, 12131, 2213, 2487, 2094, 1006, 18677, 1010, 20383, 1027, 1015, 2063, 1011, 5709, 1010, 11071, 1027, 1014, 1012, 1015, 1010, 21358, 23460, 1027, 2995, 1010, 2650, 1035, 2770, 1035, 26319, 1027, 2995, 1007, 1006, 1018, 1007, 1024, 17271, 16363, 7630, 1006, 4997, 1035, 9663, 1027, 1014, 1012, 5890, 1007, 1006, 1019, 1007, 1024, 9530, 2615, 2475, 2094, 1006, 1015, 1010, 2423, 1010, 16293, 1035, 2946, 1027, 1006, 1017, 1010, 1017, 1007, 1010, 18045, 1027, 1006, 1015, 1010, 1015, 1007, 1010, 11687, 4667, 1027, 1006, 1015, 1010, 1015, 1007, 1007, 1006, 1020, 1007, 1024, 4530, 5833, 1006, 1052, 1027, 1014, 1012, 12963, 21057, 22203, 2620, 20842, 28311, 17465, 15136, 2683, 1010, 1999, 24759, 10732, 1027, 6270, 1007, 1006, 1021, 1007, 1024, 7399, 1006, 1999, 1035, 2838, 1027, 6640, 2581, 19317, 2629, 1010, 2041, 1035, 2838, 1027, 1022, 1010, 13827, 1027, 2995, 1007, 1007]\n",
            "Output IDs: [2023, 15756, 2897, 3138, 2019, 7953, 1997, 4338, 1006, 1038, 1010, 4229, 17914, 2683, 1007, 1998, 7137, 2019, 6434, 1997, 4338, 1006, 1038, 1010, 1022, 1007, 1012, 2009, 3774, 1997, 1022, 9014, 1010, 2164, 1037, 7399, 6741, 1006, 4229, 17914, 2683, 1011, 1028, 2656, 1007, 1010, 1037, 17271, 2100, 2128, 7630, 13791, 1006, 4997, 1035, 9663, 1027, 1014, 1012, 5890, 1007, 1010, 1037, 7399, 6741, 1006, 6163, 2575, 1011, 1028, 18677, 1007, 1010, 1037, 1015, 2094, 14108, 3671, 3989, 1006, 16371, 2213, 1035, 2838, 1027, 18677, 1007, 1010, 1037, 17271, 2100, 2128, 7630, 13791, 1006, 4997, 1035, 9663, 1027, 1014, 1012, 5890, 1007, 1010, 1037, 14134, 9530, 6767, 7630, 3508, 2389, 6741, 1006, 1015, 1011, 1028, 2423, 1010, 16293, 1035, 2946, 1027, 1006, 1017, 1010, 1017, 1007, 1007, 1010, 1037, 4530, 5833, 6741, 1006, 1052, 1027, 1014, 1012, 2260, 1007, 1010, 1037, 7399, 6741, 1006, 6640, 2581, 19317, 2629, 1011, 1028, 1022, 1007, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_3p-zvJqtoF",
        "outputId": "ac99cc92-ac5f-4995-b131-61032eac5049"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"/content/drive/MyDrive/ShodhAI/data_10k.json\", \"r\") as f:\n",
        "  data = json.load(f)"
      ],
      "metadata": {
        "id": "7W3yli2yraOF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDbsvTP6rhhb",
        "outputId": "97d216df-ca6e-4959-d21a-9bfee95b6b28"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SyntheticDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=512):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_text, output_text = self.data[idx]\n",
        "\n",
        "        # Tokenize input and output texts\n",
        "        input_encoding = self.tokenizer(input_text, return_tensors='pt', max_length=self.max_length, truncation=True, padding='max_length')\n",
        "        output_encoding = self.tokenizer(output_text, return_tensors='pt', max_length=self.max_length, truncation=True, padding='max_length')\n",
        "\n",
        "        # Extract input and output IDs\n",
        "        input_ids = input_encoding['input_ids'].squeeze(0)  # Remove batch dimension\n",
        "        output_ids = output_encoding['input_ids'].squeeze(0)  # Remove batch dimension\n",
        "\n",
        "        return input_ids, output_ids\n",
        "\n",
        "# # Initialize the tokenizer\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# # Example data\n",
        "# example_input = \"Sequential((0): Linear(in_features=38809, out_features=26, bias=True) (1): LeakyReLU(negative_slope=0.01) (2): Linear(in_features=676, out_features=183, bias=True) (3): BatchNorm1d(183, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (4): LeakyReLU(negative_slope=0.01) (5): Conv2d(1, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (6): Dropout(p=0.11890518865721189, inplace=False) (7): Linear(in_features=837225, out_features=8, bias=True))\"\n",
        "# example_output = \"This neural network takes an input of shape (b,38809) and produces an output of shape (b,8). It consists of 8 layers, including a Linear layer (38809 -> 26), a Leaky ReLU activation (negative_slope=0.01), a Linear layer (676 -> 183), a 1D Batch Normalization (num_features=183), a Leaky ReLU activation (negative_slope=0.01), a 2D Convolutional layer (1 -> 25, kernel_size=(3, 3)), a Dropout layer (p=0.12), a Linear layer (837225 -> 8).\"\n",
        "\n",
        "# # Create dataset\n",
        "# # data = [(example_input, example_output)]\n",
        "# # data = [(str(sample_df[-1][0]), sample_df[-1][1])]\n",
        "# # data = [(str(sample_df[i][0]), sample_df[i][1]) for i in range(len(sample_df))]\n",
        "# dataset = SyntheticDataset(data, tokenizer)\n",
        "\n",
        "# # Create DataLoader\n",
        "# dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# # Print the first batch to verify\n",
        "# for batch in dataloader:\n",
        "#     src, tgt = batch\n",
        "#     print(\"Source Shape:\", src.shape)\n",
        "#     print(\"Target Shape:\", tgt.shape)\n",
        "#     break\n"
      ],
      "metadata": {
        "id": "Xi6tCp11jAp1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = TransformerSeq2Seq(len(tokenizer.vocab), len(tokenizer.vocab)).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(model, dataloader, optimizer, criterion, num_epochs=10):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for src, tgt in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(src, tgt[:-1, :])\n",
        "            output = output.reshape(-1, output.shape[2])\n",
        "            tgt = tgt[1:, :].reshape(-1)\n",
        "\n",
        "            loss = criterion(output, tgt)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Loss: {epoch_loss / len(dataloader)}')\n",
        "\n",
        "# Train the model\n",
        "# train(model, dataloader, optimizer, criterion, num_epochs=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwHKeyRqisLk",
        "outputId": "0fd23c7d-fe37-4086-e8ca-3ff7bb63d95f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def train_with_checkpointing(model, dataloader, optimizer, criterion, num_epochs=10, patience=3, checkpoint_path='/content/drive/MyDrive/ShodhAI/checkpoint_10k.pt'):\n",
        "    model.train()\n",
        "    best_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for src, tgt in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(src, tgt[:-1, :])\n",
        "            output = output.reshape(-1, output.shape[2])\n",
        "            tgt = tgt[1:, :].reshape(-1)\n",
        "\n",
        "            loss = criterion(output, tgt)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_epoch_loss = epoch_loss / len(dataloader)\n",
        "        print(f'Epoch {epoch+1}, Loss: {avg_epoch_loss}')\n",
        "\n",
        "        # Checkpointing\n",
        "        if avg_epoch_loss < best_loss:\n",
        "            best_loss = avg_epoch_loss\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve == patience:\n",
        "                print('Early stopping')\n",
        "                break\n",
        "\n",
        "# Train the model with checkpointing\n",
        "train_with_checkpointing(model, dataloader, optimizer, criterion, num_epochs=30, patience=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dhZqSnFi6bL",
        "outputId": "48f3030c-3b46-419b-c6aa-6e51d4cb4bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6180945810198784\n",
            "Epoch 2, Loss: 0.097610805529356\n",
            "Epoch 3, Loss: 0.08348393940925598\n",
            "Epoch 4, Loss: 0.0763464922040701\n",
            "Epoch 5, Loss: 0.0732186341047287\n",
            "Epoch 6, Loss: 0.0722442261248827\n",
            "Epoch 7, Loss: 0.06970787583440542\n",
            "Epoch 8, Loss: 0.06800505463927985\n",
            "Epoch 9, Loss: 0.06792219555974006\n",
            "Epoch 10, Loss: 0.07015236134380103\n",
            "Epoch 11, Loss: 0.06713637594282627\n",
            "Epoch 12, Loss: 0.06677133762836457\n",
            "Epoch 13, Loss: 0.066130644659698\n",
            "Epoch 14, Loss: 0.08204391510486603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "def calculate_metrics(predictions, targets, tokenizer):\n",
        "    print(\"prediction\", predictions)\n",
        "    print(\"targets\", targets)\n",
        "    pred_tokens = [pred.split() for pred in predictions]\n",
        "    target_tokens = [tgt.split() for tgt in targets]\n",
        "    # Flatten the list of lists\n",
        "    pred_flat = [token for sent in pred_tokens for token in sent]\n",
        "    target_flat = [token for sent in target_tokens for token in sent]\n",
        "    ##Adjust the dimention\n",
        "    length = min(len(pred_flat), len(target_flat))\n",
        "    pred_flat = pred_flat[:length]\n",
        "    target_flat = target_flat[:length]\n",
        "    print(\"*\"*50)\n",
        "    print(pred_flat, target_flat)\n",
        "    print(\"*\"*50)\n",
        "    # Convert tokens to IDs\n",
        "    pred_ids = tokenizer.convert_tokens_to_ids(pred_flat)\n",
        "    target_ids = tokenizer.convert_tokens_to_ids(target_flat)\n",
        "\n",
        "    # Ensure we use the same set of unique tokens for both\n",
        "    unique_tokens = list(set(pred_ids + target_ids))\n",
        "\n",
        "    # Calculate precision, recall, and F1-score\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(target_ids, pred_ids, labels=unique_tokens, average='weighted')\n",
        "    accuracy = accuracy_score(target_ids, pred_ids)\n",
        "\n",
        "    return precision, recall, f1, accuracy\n",
        "\n",
        "def test_model(model, tokenizer, test_data, batch_size=32):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Prepare DataLoader for testing\n",
        "    test_dataset = SyntheticDataset(test_data, tokenizer)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (src, tgt) in enumerate(test_dataloader):\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "\n",
        "            # Generate predictions\n",
        "            output = model(src, tgt[:-1, :])  # Remove last token from target for prediction\n",
        "            predicted_ids = torch.argmax(output, dim=-1)\n",
        "\n",
        "            # Convert predicted IDs to tokens\n",
        "            predicted_tokens = tokenizer.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "            target_tokens = tokenizer.batch_decode(tgt, skip_special_tokens=True)\n",
        "\n",
        "            # Store predictions and targets\n",
        "            all_predictions.extend(predicted_tokens)\n",
        "            all_targets.extend(target_tokens)\n",
        "\n",
        "    # Compute F1 score\n",
        "    precision, recall, f1, accuracy = calculate_metrics(all_predictions, all_targets, tokenizer)\n",
        "\n",
        "    return precision, recall, f1, accuracy\n",
        "\n",
        "def main():\n",
        "    # Initialize tokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    test_data = generate_dataset(20) # [(example source, example_target)]\n",
        "\n",
        "    # Initialize and load your TransformerSeq2Seq model\n",
        "    model = TransformerSeq2Seq(input_dim=len(tokenizer.vocab), output_dim=len(tokenizer.vocab))\n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/ShodhAI/checkpoint.pt', map_location=torch.device('cpu')))  # Load your trained model checkpoint `map_location=torch.device('cpu')` on cpu\n",
        "    # model.to(device)\n",
        "\n",
        "    # Test the model\n",
        "    precision, recall, f1, accuracy = test_model(model, tokenizer, test_data)\n",
        "\n",
        "    print(\"precision\", precision)\n",
        "    print(\"Recall\", recall)\n",
        "    print(\"f1 score\", f1)\n",
        "    print(\"accuracy\", accuracy)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc1PhD_KtMSw",
        "outputId": "13f7dd65-6033-4b9a-d8f6-3c8c2fbe46f6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction ['this neural network takes an input of shape ( b, 46875 ) and produces an output of shape ( b, 7 ). it consists of 6 layers, including a linear layer ( 46875 - > 125 ), a dropout layer ( p = 0. 39 ), a linear layer ( 15625 - > 7 ), a 1d batch normalization ( num _ features = 7 ), a dropout layer ( p = 0. 36 ), a linear layer ( 49 - > 7 ).', 'this neural network takes an input of shape ( b, 1, w ) and produces an output of shape ( b, 5 ). it consists of 10 layers, including a 1d convolutional layer ( 1 - > 54, kernel _ size = 3 ), a 2d convolutional layer ( 54 - > 54, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 24 ), a 2d convolutional layer ( 54 - > 34, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 34 ), a tanh activation, a linear layer ( 903346 - > 5 ), a 1d batch normalization ( num _ features = 5 ), a dropout layer ( p = 0. 43 ), a linear layer ( 25 - > 5 ).', 'this neural network takes an input of shape ( b, 1, h, w ) and produces an output of shape ( b, 1 ). it consists of 8 layers, including a 2d convolutional layer ( 1 - > 17, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 47 ), a 2d convolutional layer ( 17 - > 56, kernel _ size = ( 3, 3 ) ), a tanh activation, a 1d convolutional layer ( 56 - > 16, kernel _ size = 3 ), a sigmoid activation, a dropout layer ( p = 0. 41 ), a linear layer ( 419904 - > 1 ).', 'this neural network takes an input of shape ( b, 1, w ) and produces an output of shape ( b, 7 ). it consists of 13 layers, including a 1d convolutional layer ( 1 - > 41, kernel _ size = 3 ), a dropout layer ( p = 0. 46 ), a 2d convolutional layer ( 41 - > 17, kernel _ size = ( 3, 3 ) ), a relu activation, a 1d convolutional layer ( 17 - > 27, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 27 ), a sigmoid activation, a 2d convolutional layer ( 27 - > 59, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 59 ), a linear layer ( 59 - > 7 ), a 1d batch normalization ( num _ features = 7 ), a dropout layer ( p = 0. 49 ), a linear layer ( 49 - > 7 ).', 'this neural network takes an input of shape ( b, 10 ) and produces an output of shape ( b, 5 ). it consists of 9 layers, including a linear layer ( 10 - > 197 ), a sigmoid activation, a linear layer ( 38809 - > 173 ), a 1d batch normalization ( num _ features = 173 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 29929 - > 5 ), a 1d batch normalization ( num _ features = 5 ), a dropout layer ( p = 0. 37 ), a linear layer ( 25 - > 5 ).', 'this neural network takes an input of shape ( b, 10658 ) and produces an output of shape ( b, 5 ). it consists of 15 layers, including a linear layer ( 10658 - > 166 ), a 1d batch normalization ( num _ features = 166 ), a dropout layer ( p = 0. 11 ), a 1d convolutional layer ( 1 - > 44, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 44 ), a 2d convolutional layer ( 44 - > 50, kernel _ size = ( 3, 3 ) ), a sigmoid activation, a 1d convolutional layer ( 50 - > 30, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 30 ), a relu activation, a dropout layer ( p = 0. 28 ), a linear layer ( 826680 - > 5 ), a 1d batch normalization ( num _ features = 5 ), a dropout layer ( p = 0. 47 ), a linear layer ( 25 - > 5 ).', 'this neural network takes an input of shape ( b, 2, w ) and produces an output of shape ( b, 4 ). it consists of 12 layers, including a 1d convolutional layer ( 2 - > 23, kernel _ size = 3 ), a 2d convolutional layer ( 23 - > 22, kernel _ size = ( 3, 3 ) ), a 1d convolutional layer ( 22 - > 32, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 32 ), a sigmoid activation, a dropout layer ( p = 0. 11 ), a linear layer ( 36992 - > 124 ), a linear layer ( 124 - > 4 ), a 1d batch normalization ( num _ features = 4 ), a tanh activation, a dropout layer ( p = 0. 22 ), a linear layer ( 16 - > 4 ).', 'this neural network takes an input of shape ( b, 3, w ) and produces an output of shape ( b, 7 ). it consists of 9 layers, including a 1d convolutional layer ( 3 - > 36, kernel _ size = 3 ), a relu activation, a dropout layer ( p = 0. 28 ), a 1d convolutional layer ( 36 - > 16, kernel _ size = 3 ), a 1d convolutional layer ( 16 - > 41, kernel _ size = 3 ), a relu activation, a linear layer ( 1591169 - > 7 ), a dropout layer ( p = 0. 28 ), a linear layer ( 49 - > 7 ).', 'this neural network takes an input of shape ( b, 1, h, w ) and produces an output of shape ( b, 2 ). it consists of 7 layers, including a 2d convolutional layer ( 1 - > 21, kernel _ size = ( 3, 3 ) ), a relu activation, a dropout layer ( p = 0. 26 ), a 1d convolutional layer ( 21 - > 28, kernel _ size = 3 ), a linear layer ( 28 - > 2 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 4 - > 2 ).', 'this neural network takes an input of shape ( b, 2, h, w ) and produces an output of shape ( b, 9 ). it consists of 15 layers, including a 2d convolutional layer ( 2 - > 39, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 39 ), a 1d convolutional layer ( 39 - > 35, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 35 ), a leaky relu activation ( negative _ slope = 0. 01 ), a dropout layer ( p = 0. 39 ), a 1d convolutional layer ( 35 - > 16, kernel _ size = 3 ), a dropout layer ( p = 0. 30 ), a 1d convolutional layer ( 16 - > 37, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 37 ), a tanh activation, a dropout layer ( p = 0. 26 ), a linear layer ( 1172308 - > 9 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 81 - > 9 ).', 'this neural network takes an input of shape ( b, 1, w ) and produces an output of shape ( b, 5 ). it consists of 16 layers, including a 1d convolutional layer ( 1 - > 46, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 46 ), a leaky relu activation ( negative _ slope = 0. 01 ), a dropout layer ( p = 0. 37 ), a 2d convolutional layer ( 46 - > 57, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 57 ), a leaky relu activation ( negative _ slope = 0. 01 ), a dropout layer ( p = 0. 49 ), a 1d convolutional layer ( 57 - > 20, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 20 ), a relu activation, a dropout layer ( p = 0. 26 ), a linear layer ( negative820 - > 5 ), a 1d batch normalization ( num _ features = 5 ), a tanh activation, a linear layer ( 25 - > 5 ).', 'this neural network takes an input of shape ( b, 1, h, w ) and produces an output of shape ( b, 1 ). it consists of 5 layers, including a 2d convolutional layer ( 1 - > 46, kernel _ size = ( 3, 3 ) ), a linear layer ( 46 - > 1 ), a 1d batch normalization ( num _ features = 1 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 1 - > 1 ).', 'this neural network takes an input of shape ( b, 2, h, w ) and produces an output of shape ( b, 4 ). it consists of 7 layers, including a 2d convolutional layer ( 2 - > 63, kernel _ size = ( 3, 3 ) ), a 2d convolutional layer ( 63 - > 52, kernel _ size = ( 3, 3 ) ), a 2d convolutional layer ( 52 - > 58, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 58 ), a leaky relu activation ( negative _ slope = 0. 01 ), a dropout layer ( p = 0. 16 ), a linear layer ( kernel250 - > 4 ).', 'this neural network takes an input of shape ( b, 2, h, w ) and produces an output of shape ( b, 7 ). it consists of 11 layers, including a 2d convolutional layer ( 2 - > 51, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 51 ), a linear layer ( 51 - > 99 ), a dropout layer ( p = 0. 12 ), a 2d convolutional layer ( 1 - > 23, kernel _ size = ( 3, 3 ) ), a linear layer ( 23 - > 22 ), a 1d batch normalization ( num _ features = 22 ), a linear layer ( 22 - > 7 ), a 1d batch normalization ( num _ features = 7 ), a dropout layer ( p = 0. 45 ), a linear layer ( 49 - > 7 ).', 'this neural network takes an input of shape ( b, 2, w ) and produces output output of output ( b, b ). it consists it consists layers, including a 1d convolutional layer ( 1 - > >, kernel _ size = 3 ), a 3 ) ), a ( layerm _ ( = 0 ), ), =,,, ( ) ), ( ( ),,, ( ( ( = ), a, ),, a a ) (lu ( ( ) layer, ),,,,,,', 'this neural network takes an input of shape ( b, 1, w, and ) and output an shape ( shape ( b ). ). it consists layers, layers, 1d 2d convolution layer layer ( 1 - >, kernel kernel size = 3 ),, 3 ) ), a ( layer ( 4 ) >m ) kernel _ 1 ) ( layer, ( ) ) 3 a 0 ) ) ), ) (out ) ), ) 3 ) = ). ( ) ),lu )d layer ) ) ) )m _ kernel 3 ) ), ) ) ) ) layer ) numm ) )m ) =. ) ) ) ) )', 'this neural network takes an input of shape ( b, 1, h, and ) and output of output ( b ( b,. it consists of consists of, including a 1 a 2dvovolual layer layer 1 - - >,, _ _ = 3 ( 3, 3 ) ), a 2d batch ( _ ( nu 11 _ kernel _ size a ( a kernel layer nu _ _ ( ( ( layer, _ _ _ ( ( ), a _ ) _ _ a 1 layer ( _ a (al 1 - _ - kernel _ _ kernel _ layer =, _ _ _ 1 ( layer drop _ nu ( _ ) layer drop ) ) a p layer', 'this neural network takes an input of shape ( b, 1, h, and produces and output an output of b ( b,. it consists it consists of including including, includingd 2d convotiontional ( ( 1 - >,, kernel _ = = ( 3, 3 ) ), a 2d layer (lu ( > 0 _ kernel _ 1 = ( (, ( ( ) - > (, layer,, _ ( = ( ), a 1 ( batch, 2d ( layer (lulution59, ( > ( > ( _ kernel = size (,,, ( ( ( nuization _ ( a 27lu', 'this neural network takes an input of shape ( b, 1, h ) and produces output output of output ( b, b ). it consists it consists layers, including a 1d 2dvovolution layer ( 1 - - >, kernel _ _ = = ), a 3 ) ), a drop layer (ization - = 0 ) ( _ 1dizationlulu ( ) layer - layer =lu layer, layer (y (lu ( 3 layer _ ) ), size, a convolu layer - 1 - > - ) kernely kernel _ ),, )ization (']\n",
            "targets ['this neural network takes an input of shape ( b, 2, h, w ) and produces an output of shape ( b, 1 ). it consists of 6 layers, including a 2d convolutional layer ( 2 - > 39, kernel _ size = ( 3, 3 ) ), a sigmoid activation, a dropout layer ( p = 0. 36 ), a linear layer ( 344604 - > 1 ), a 1d batch normalization ( num _ features = 1 ), a linear layer ( 1 - > 1 ).', 'this neural network takes an input of shape ( b, 46875 ) and produces an output of shape ( b, 7 ). it consists of 6 layers, including a linear layer ( 46875 - > 125 ), a dropout layer ( p = 0. 39 ), a linear layer ( 15625 - > 7 ), a 1d batch normalization ( num _ features = 7 ), a dropout layer ( p = 0. 36 ), a linear layer ( 49 - > 7 ).', 'this neural network takes an input of shape ( b, 1, w ) and produces an output of shape ( b, 5 ). it consists of 10 layers, including a 1d convolutional layer ( 1 - > 54, kernel _ size = 3 ), a 2d convolutional layer ( 54 - > 54, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 24 ), a 2d convolutional layer ( 54 - > 34, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 34 ), a tanh activation, a linear layer ( 903346 - > 5 ), a 1d batch normalization ( num _ features = 5 ), a dropout layer ( p = 0. 43 ), a linear layer ( 25 - > 5 ).', 'this neural network takes an input of shape ( b, 1, h, w ) and produces an output of shape ( b, 1 ). it consists of 8 layers, including a 2d convolutional layer ( 1 - > 17, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 47 ), a 2d convolutional layer ( 17 - > 56, kernel _ size = ( 3, 3 ) ), a tanh activation, a 1d convolutional layer ( 56 - > 16, kernel _ size = 3 ), a sigmoid activation, a dropout layer ( p = 0. 41 ), a linear layer ( 419904 - > 1 ).', 'this neural network takes an input of shape ( b, 1, w ) and produces an output of shape ( b, 7 ). it consists of 13 layers, including a 1d convolutional layer ( 1 - > 41, kernel _ size = 3 ), a dropout layer ( p = 0. 46 ), a 2d convolutional layer ( 41 - > 17, kernel _ size = ( 3, 3 ) ), a relu activation, a 1d convolutional layer ( 17 - > 27, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 27 ), a sigmoid activation, a 2d convolutional layer ( 27 - > 59, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 59 ), a linear layer ( 59 - > 7 ), a 1d batch normalization ( num _ features = 7 ), a dropout layer ( p = 0. 49 ), a linear layer ( 49 - > 7 ).', 'this neural network takes an input of shape ( b, 20000 ) and produces an output of shape ( b, 5 ). it consists of 9 layers, including a linear layer ( 20000 - > 197 ), a sigmoid activation, a linear layer ( 38809 - > 173 ), a 1d batch normalization ( num _ features = 173 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 29929 - > 5 ), a 1d batch normalization ( num _ features = 5 ), a dropout layer ( p = 0. 37 ), a linear layer ( 25 - > 5 ).', 'this neural network takes an input of shape ( b, 10658 ) and produces an output of shape ( b, 5 ). it consists of 15 layers, including a linear layer ( 10658 - > 166 ), a 1d batch normalization ( num _ features = 166 ), a dropout layer ( p = 0. 11 ), a 1d convolutional layer ( 1 - > 44, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 44 ), a 2d convolutional layer ( 44 - > 50, kernel _ size = ( 3, 3 ) ), a sigmoid activation, a 1d convolutional layer ( 50 - > 30, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 30 ), a relu activation, a dropout layer ( p = 0. 28 ), a linear layer ( 826680 - > 5 ), a 1d batch normalization ( num _ features = 5 ), a dropout layer ( p = 0. 47 ), a linear layer ( 25 - > 5 ).', 'this neural network takes an input of shape ( b, 2, w ) and produces an output of shape ( b, 4 ). it consists of 12 layers, including a 1d convolutional layer ( 2 - > 23, kernel _ size = 3 ), a 2d convolutional layer ( 23 - > 22, kernel _ size = ( 3, 3 ) ), a 1d convolutional layer ( 22 - > 32, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 32 ), a sigmoid activation, a dropout layer ( p = 0. 11 ), a linear layer ( 36992 - > 124 ), a linear layer ( 124 - > 4 ), a 1d batch normalization ( num _ features = 4 ), a tanh activation, a dropout layer ( p = 0. 22 ), a linear layer ( 16 - > 4 ).', 'this neural network takes an input of shape ( b, 3, w ) and produces an output of shape ( b, 7 ). it consists of 9 layers, including a 1d convolutional layer ( 3 - > 36, kernel _ size = 3 ), a relu activation, a dropout layer ( p = 0. 28 ), a 1d convolutional layer ( 36 - > 16, kernel _ size = 3 ), a 1d convolutional layer ( 16 - > 41, kernel _ size = 3 ), a relu activation, a linear layer ( 1591169 - > 7 ), a dropout layer ( p = 0. 28 ), a linear layer ( 49 - > 7 ).', 'this neural network takes an input of shape ( b, 1, h, w ) and produces an output of shape ( b, 2 ). it consists of 7 layers, including a 2d convolutional layer ( 1 - > 21, kernel _ size = ( 3, 3 ) ), a relu activation, a dropout layer ( p = 0. 26 ), a 1d convolutional layer ( 21 - > 28, kernel _ size = 3 ), a linear layer ( 28 - > 2 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 4 - > 2 ).', 'this neural network takes an input of shape ( b, 2, h, w ) and produces an output of shape ( b, 9 ). it consists of 15 layers, including a 2d convolutional layer ( 2 - > 39, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 39 ), a 1d convolutional layer ( 39 - > 35, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 35 ), a leaky relu activation ( negative _ slope = 0. 01 ), a dropout layer ( p = 0. 39 ), a 1d convolutional layer ( 35 - > 16, kernel _ size = 3 ), a dropout layer ( p = 0. 30 ), a 1d convolutional layer ( 16 - > 37, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 37 ), a tanh activation, a dropout layer ( p = 0. 26 ), a linear layer ( 1172308 - > 9 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 81 - > 9 ).', 'this neural network takes an input of shape ( b, 1, w ) and produces an output of shape ( b, 5 ). it consists of 16 layers, including a 1d convolutional layer ( 1 - > 46, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 46 ), a leaky relu activation ( negative _ slope = 0. 01 ), a dropout layer ( p = 0. 37 ), a 2d convolutional layer ( 46 - > 57, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 57 ), a leaky relu activation ( negative _ slope = 0. 01 ), a dropout layer ( p = 0. 49 ), a 1d convolutional layer ( 57 - > 20, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 20 ), a relu activation, a dropout layer ( p = 0. 26 ), a linear layer ( 332820 - > 5 ), a 1d batch normalization ( num _ features = 5 ), a tanh activation, a linear layer ( 25 - > 5 ).', 'this neural network takes an input of shape ( b, 1, h, w ) and produces an output of shape ( b, 1 ). it consists of 5 layers, including a 2d convolutional layer ( 1 - > 46, kernel _ size = ( 3, 3 ) ), a linear layer ( 46 - > 1 ), a 1d batch normalization ( num _ features = 1 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 1 - > 1 ).', 'this neural network takes an input of shape ( b, 2, h, w ) and produces an output of shape ( b, 4 ). it consists of 7 layers, including a 2d convolutional layer ( 2 - > 63, kernel _ size = ( 3, 3 ) ), a 2d convolutional layer ( 63 - > 52, kernel _ size = ( 3, 3 ) ), a 2d convolutional layer ( 52 - > 58, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 58 ), a leaky relu activation ( negative _ slope = 0. 01 ), a dropout layer ( p = 0. 16 ), a linear layer ( 1776250 - > 4 ).', 'this neural network takes an input of shape ( b, 2, h, w ) and produces an output of shape ( b, 7 ). it consists of 11 layers, including a 2d convolutional layer ( 2 - > 51, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 51 ), a linear layer ( 51 - > 99 ), a dropout layer ( p = 0. 12 ), a 2d convolutional layer ( 1 - > 23, kernel _ size = ( 3, 3 ) ), a linear layer ( 23 - > 22 ), a 1d batch normalization ( num _ features = 22 ), a linear layer ( 22 - > 7 ), a 1d batch normalization ( num _ features = 7 ), a dropout layer ( p = 0. 45 ), a linear layer ( 49 - > 7 ).', 'this neural network takes an input of shape ( b, 42025 ) and produces an output of shape ( b, 1 ). it consists of 16 layers, including a linear layer ( 42025 - > 72 ), a tanh activation, a dropout layer ( p = 0. 35 ), a 1d convolutional layer ( 1 - > 40, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 40 ), a 1d convolutional layer ( 40 - > 30, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 30 ), a sigmoid activation, a dropout layer ( p = 0. 49 ), a 1d convolutional layer ( 30 - > 30, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 30 ), a dropout layer ( p = 0. 34 ), a linear layer ( 155520 - > 1 ), a tanh activation, a dropout layer ( p = 0. 14 ), a linear layer ( 1 - > 1 ).', 'this neural network takes an input of shape ( b, 88200 ) and produces an output of shape ( b, 7 ). it consists of 9 layers, including a linear layer ( 88200 - > 180 ), a dropout layer ( p = 0. 49 ), a 2d convolutional layer ( 1 - > 47, kernel _ size = ( 3, 3 ) ), a sigmoid activation, a dropout layer ( p = 0. 39 ), a linear layer ( 1522800 - > 7 ), a sigmoid activation, a dropout layer ( p = 0. 44 ), a linear layer ( 49 - > 7 ).', 'this neural network takes an input of shape ( b, 1, w ) and produces an output of shape ( b, 2 ). it consists of 10 layers, including a 1d convolutional layer ( 1 - > 55, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 55 ), a 2d convolutional layer ( 55 - > 51, kernel _ size = ( 3, 3 ) ), a tanh activation, a linear layer ( 189771 - > 16 ), a 1d batch normalization ( num _ features = 16 ), a dropout layer ( p = 0. 14 ), a linear layer ( 256 - > 2 ), a 1d batch normalization ( num _ features = 2 ), a linear layer ( 2 - > 2 ).', 'this neural network takes an input of shape ( b, 1, h, w ) and produces an output of shape ( b, 6 ). it consists of 7 layers, including a 2d convolutional layer ( 1 - > 23, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 23 ), a linear layer ( 23 - > 177 ), a linear layer ( 177 - > 6 ), a 1d batch normalization ( num _ features = 6 ), a dropout layer ( p = 0. 37 ), a linear layer ( 36 - > 6 ).', 'this neural network takes an input of shape ( b, 47432 ) and produces an output of shape ( b, 5 ). it consists of 11 layers, including a linear layer ( 47432 - > 106 ), a 1d batch normalization ( num _ features = 106 ), a relu activation, a dropout layer ( p = 0. 37 ), a 1d convolutional layer ( 1 - > 44, kernel _ size = 3 ), a relu activation, a linear layer ( 494384 - > 5 ), a 1d batch normalization ( num _ features = 5 ), a tanh activation, a dropout layer ( p = 0. 42 ), a linear layer ( 25 - > 5 ).']\n",
            "**************************************************\n",
            "['this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '46875', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '7', ').', 'it', 'consists', 'of', '6', 'layers,', 'including', 'a', 'linear', 'layer', '(', '46875', '-', '>', '125', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '39', '),', 'a', 'linear', 'layer', '(', '15625', '-', '>', '7', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '7', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '36', '),', 'a', 'linear', 'layer', '(', '49', '-', '>', '7', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '5', ').', 'it', 'consists', 'of', '10', 'layers,', 'including', 'a', '1d', 'convolutional', 'layer', '(', '1', '-', '>', '54,', 'kernel', '_', 'size', '=', '3', '),', 'a', '2d', 'convolutional', 'layer', '(', '54', '-', '>', '54,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '24', '),', 'a', '2d', 'convolutional', 'layer', '(', '54', '-', '>', '34,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '34', '),', 'a', 'tanh', 'activation,', 'a', 'linear', 'layer', '(', '903346', '-', '>', '5', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '5', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '43', '),', 'a', 'linear', 'layer', '(', '25', '-', '>', '5', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '1', ').', 'it', 'consists', 'of', '8', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '1', '-', '>', '17,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '47', '),', 'a', '2d', 'convolutional', 'layer', '(', '17', '-', '>', '56,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'tanh', 'activation,', 'a', '1d', 'convolutional', 'layer', '(', '56', '-', '>', '16,', 'kernel', '_', 'size', '=', '3', '),', 'a', 'sigmoid', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '41', '),', 'a', 'linear', 'layer', '(', '419904', '-', '>', '1', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '7', ').', 'it', 'consists', 'of', '13', 'layers,', 'including', 'a', '1d', 'convolutional', 'layer', '(', '1', '-', '>', '41,', 'kernel', '_', 'size', '=', '3', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '46', '),', 'a', '2d', 'convolutional', 'layer', '(', '41', '-', '>', '17,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'relu', 'activation,', 'a', '1d', 'convolutional', 'layer', '(', '17', '-', '>', '27,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '27', '),', 'a', 'sigmoid', 'activation,', 'a', '2d', 'convolutional', 'layer', '(', '27', '-', '>', '59,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '59', '),', 'a', 'linear', 'layer', '(', '59', '-', '>', '7', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '7', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '49', '),', 'a', 'linear', 'layer', '(', '49', '-', '>', '7', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '10', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '5', ').', 'it', 'consists', 'of', '9', 'layers,', 'including', 'a', 'linear', 'layer', '(', '10', '-', '>', '197', '),', 'a', 'sigmoid', 'activation,', 'a', 'linear', 'layer', '(', '38809', '-', '>', '173', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '173', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'linear', 'layer', '(', '29929', '-', '>', '5', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '5', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '37', '),', 'a', 'linear', 'layer', '(', '25', '-', '>', '5', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '10658', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '5', ').', 'it', 'consists', 'of', '15', 'layers,', 'including', 'a', 'linear', 'layer', '(', '10658', '-', '>', '166', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '166', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '11', '),', 'a', '1d', 'convolutional', 'layer', '(', '1', '-', '>', '44,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '44', '),', 'a', '2d', 'convolutional', 'layer', '(', '44', '-', '>', '50,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'sigmoid', 'activation,', 'a', '1d', 'convolutional', 'layer', '(', '50', '-', '>', '30,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '30', '),', 'a', 'relu', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '28', '),', 'a', 'linear', 'layer', '(', '826680', '-', '>', '5', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '5', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '47', '),', 'a', 'linear', 'layer', '(', '25', '-', '>', '5', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '4', ').', 'it', 'consists', 'of', '12', 'layers,', 'including', 'a', '1d', 'convolutional', 'layer', '(', '2', '-', '>', '23,', 'kernel', '_', 'size', '=', '3', '),', 'a', '2d', 'convolutional', 'layer', '(', '23', '-', '>', '22,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '1d', 'convolutional', 'layer', '(', '22', '-', '>', '32,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '32', '),', 'a', 'sigmoid', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '11', '),', 'a', 'linear', 'layer', '(', '36992', '-', '>', '124', '),', 'a', 'linear', 'layer', '(', '124', '-', '>', '4', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '4', '),', 'a', 'tanh', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '22', '),', 'a', 'linear', 'layer', '(', '16', '-', '>', '4', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '3,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '7', ').', 'it', 'consists', 'of', '9', 'layers,', 'including', 'a', '1d', 'convolutional', 'layer', '(', '3', '-', '>', '36,', 'kernel', '_', 'size', '=', '3', '),', 'a', 'relu', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '28', '),', 'a', '1d', 'convolutional', 'layer', '(', '36', '-', '>', '16,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'convolutional', 'layer', '(', '16', '-', '>', '41,', 'kernel', '_', 'size', '=', '3', '),', 'a', 'relu', 'activation,', 'a', 'linear', 'layer', '(', '1591169', '-', '>', '7', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '28', '),', 'a', 'linear', 'layer', '(', '49', '-', '>', '7', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '2', ').', 'it', 'consists', 'of', '7', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '1', '-', '>', '21,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'relu', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '26', '),', 'a', '1d', 'convolutional', 'layer', '(', '21', '-', '>', '28,', 'kernel', '_', 'size', '=', '3', '),', 'a', 'linear', 'layer', '(', '28', '-', '>', '2', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'linear', 'layer', '(', '4', '-', '>', '2', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '9', ').', 'it', 'consists', 'of', '15', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '2', '-', '>', '39,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '39', '),', 'a', '1d', 'convolutional', 'layer', '(', '39', '-', '>', '35,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '35', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '39', '),', 'a', '1d', 'convolutional', 'layer', '(', '35', '-', '>', '16,', 'kernel', '_', 'size', '=', '3', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '30', '),', 'a', '1d', 'convolutional', 'layer', '(', '16', '-', '>', '37,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '37', '),', 'a', 'tanh', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '26', '),', 'a', 'linear', 'layer', '(', '1172308', '-', '>', '9', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'linear', 'layer', '(', '81', '-', '>', '9', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '5', ').', 'it', 'consists', 'of', '16', 'layers,', 'including', 'a', '1d', 'convolutional', 'layer', '(', '1', '-', '>', '46,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '46', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '37', '),', 'a', '2d', 'convolutional', 'layer', '(', '46', '-', '>', '57,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '57', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '49', '),', 'a', '1d', 'convolutional', 'layer', '(', '57', '-', '>', '20,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '20', '),', 'a', 'relu', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '26', '),', 'a', 'linear', 'layer', '(', 'negative820', '-', '>', '5', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '5', '),', 'a', 'tanh', 'activation,', 'a', 'linear', 'layer', '(', '25', '-', '>', '5', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '1', ').', 'it', 'consists', 'of', '5', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '1', '-', '>', '46,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'linear', 'layer', '(', '46', '-', '>', '1', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '1', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'linear', 'layer', '(', '1', '-', '>', '1', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '4', ').', 'it', 'consists', 'of', '7', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '2', '-', '>', '63,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'convolutional', 'layer', '(', '63', '-', '>', '52,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'convolutional', 'layer', '(', '52', '-', '>', '58,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '58', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '16', '),', 'a', 'linear', 'layer', '(', 'kernel250', '-', '>', '4', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '7', ').', 'it', 'consists', 'of', '11', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '2', '-', '>', '51,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '51', '),', 'a', 'linear', 'layer', '(', '51', '-', '>', '99', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '12', '),', 'a', '2d', 'convolutional', 'layer', '(', '1', '-', '>', '23,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'linear', 'layer', '(', '23', '-', '>', '22', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '22', '),', 'a', 'linear', 'layer', '(', '22', '-', '>', '7', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '7', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '45', '),', 'a', 'linear', 'layer', '(', '49', '-', '>', '7', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'w', ')', 'and', 'produces', 'output', 'output', 'of', 'output', '(', 'b,', 'b', ').', 'it', 'consists', 'it', 'consists', 'layers,', 'including', 'a', '1d', 'convolutional', 'layer', '(', '1', '-', '>', '>,', 'kernel', '_', 'size', '=', '3', '),', 'a', '3', ')', '),', 'a', '(', 'layerm', '_', '(', '=', '0', '),', '),', '=,,,', '(', ')', '),', '(', '(', '),,,', '(', '(', '(', '=', '),', 'a,', '),,', 'a', 'a', ')', '(lu', '(', '(', ')', 'layer,', '),,,,,,', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'w,', 'and', ')', 'and', 'output', 'an', 'shape', '(', 'shape', '(', 'b', ').', ').', 'it', 'consists', 'layers,', 'layers,', '1d', '2d', 'convolution', 'layer', 'layer', '(', '1', '-', '>,', 'kernel', 'kernel', 'size', '=', '3', '),,', '3', ')', '),', 'a', '(', 'layer', '(', '4', ')', '>m', ')', 'kernel', '_', '1', ')', '(', 'layer,', '(', ')', ')', '3', 'a', '0', ')', ')', '),', ')', '(out', ')', '),', ')', '3', ')', '=', ').', '(', ')', '),lu', ')d', 'layer', ')', ')', ')', ')m', '_', 'kernel', '3', ')', '),', ')', ')', ')', ')', 'layer', ')', 'numm', ')', ')m', ')', '=.', ')', ')', ')', ')', ')', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'h,', 'and', ')', 'and', 'output', 'of', 'output', '(', 'b', '(', 'b,.', 'it', 'consists', 'of', 'consists', 'of,', 'including', 'a', '1', 'a', '2dvovolual', 'layer', 'layer', '1', '-', '-', '>,,', '_', '_', '=', '3', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', '(', '_', '(', 'nu', '11', '_', 'kernel', '_', 'size', 'a', '(', 'a', 'kernel', 'layer', 'nu', '_', '_', '(', '(', '(', 'layer,', '_', '_', '_', '(', '(', '),', 'a', '_', ')', '_', '_', 'a', '1', 'layer', '(', '_', 'a', '(al', '1', '-', '_', '-', 'kernel', '_', '_', 'kernel', '_', 'layer', '=,', '_', '_', '_', '1', '(', 'layer', 'drop', '_', 'nu', '(', '_', ')', 'layer', 'drop', ')', ')', 'a', 'p', 'layer', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'h,', 'and', 'produces', 'and', 'output', 'an', 'output', 'of', 'b', '(', 'b,.', 'it', 'consists', 'it', 'consists', 'of', 'including', 'including,', 'includingd', '2d', 'convotiontional', '(', '(', '1', '-', '>,,', 'kernel', '_', '=', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'layer', '(lu', '(', '>', '0', '_', 'kernel', '_', '1', '=', '(', '(,', '(', '(', ')', '-', '>', '(,', 'layer,,', '_', '(', '=', '(', '),', 'a', '1', '(', 'batch,', '2d', '(', 'layer', '(lulution59,', '(', '>', '(', '>', '(', '_', 'kernel', '=', 'size', '(,,,', '(', '(', '(', 'nuization', '_', '(', 'a', '27lu', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'h', ')', 'and', 'produces', 'output', 'output', 'of', 'output', '(', 'b,', 'b', ').', 'it', 'consists', 'it', 'consists', 'layers,', 'including', 'a', '1d', '2dvovolution', 'layer', '(', '1', '-', '-', '>,', 'kernel', '_', '_', '=', '=', '),', 'a', '3', ')', '),', 'a', 'drop', 'layer', '(ization', '-', '=', '0', ')', '(', '_', '1dizationlulu', '(', ')', 'layer', '-', 'layer', '=lu', 'layer,', 'layer', '(y', '(lu', '(', '3', 'layer', '_', ')', '),', 'size,', 'a', 'convolu', 'layer', '-', '1', '-', '>', '-', ')', 'kernely', 'kernel', '_', '),,', ')ization', '('] ['this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '1', ').', 'it', 'consists', 'of', '6', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '2', '-', '>', '39,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'sigmoid', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '36', '),', 'a', 'linear', 'layer', '(', '344604', '-', '>', '1', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '1', '),', 'a', 'linear', 'layer', '(', '1', '-', '>', '1', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '46875', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '7', ').', 'it', 'consists', 'of', '6', 'layers,', 'including', 'a', 'linear', 'layer', '(', '46875', '-', '>', '125', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '39', '),', 'a', 'linear', 'layer', '(', '15625', '-', '>', '7', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '7', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '36', '),', 'a', 'linear', 'layer', '(', '49', '-', '>', '7', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '5', ').', 'it', 'consists', 'of', '10', 'layers,', 'including', 'a', '1d', 'convolutional', 'layer', '(', '1', '-', '>', '54,', 'kernel', '_', 'size', '=', '3', '),', 'a', '2d', 'convolutional', 'layer', '(', '54', '-', '>', '54,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '24', '),', 'a', '2d', 'convolutional', 'layer', '(', '54', '-', '>', '34,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '34', '),', 'a', 'tanh', 'activation,', 'a', 'linear', 'layer', '(', '903346', '-', '>', '5', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '5', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '43', '),', 'a', 'linear', 'layer', '(', '25', '-', '>', '5', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '1', ').', 'it', 'consists', 'of', '8', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '1', '-', '>', '17,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '47', '),', 'a', '2d', 'convolutional', 'layer', '(', '17', '-', '>', '56,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'tanh', 'activation,', 'a', '1d', 'convolutional', 'layer', '(', '56', '-', '>', '16,', 'kernel', '_', 'size', '=', '3', '),', 'a', 'sigmoid', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '41', '),', 'a', 'linear', 'layer', '(', '419904', '-', '>', '1', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '7', ').', 'it', 'consists', 'of', '13', 'layers,', 'including', 'a', '1d', 'convolutional', 'layer', '(', '1', '-', '>', '41,', 'kernel', '_', 'size', '=', '3', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '46', '),', 'a', '2d', 'convolutional', 'layer', '(', '41', '-', '>', '17,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'relu', 'activation,', 'a', '1d', 'convolutional', 'layer', '(', '17', '-', '>', '27,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '27', '),', 'a', 'sigmoid', 'activation,', 'a', '2d', 'convolutional', 'layer', '(', '27', '-', '>', '59,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '59', '),', 'a', 'linear', 'layer', '(', '59', '-', '>', '7', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '7', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '49', '),', 'a', 'linear', 'layer', '(', '49', '-', '>', '7', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '20000', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '5', ').', 'it', 'consists', 'of', '9', 'layers,', 'including', 'a', 'linear', 'layer', '(', '20000', '-', '>', '197', '),', 'a', 'sigmoid', 'activation,', 'a', 'linear', 'layer', '(', '38809', '-', '>', '173', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '173', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'linear', 'layer', '(', '29929', '-', '>', '5', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '5', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '37', '),', 'a', 'linear', 'layer', '(', '25', '-', '>', '5', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '10658', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '5', ').', 'it', 'consists', 'of', '15', 'layers,', 'including', 'a', 'linear', 'layer', '(', '10658', '-', '>', '166', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '166', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '11', '),', 'a', '1d', 'convolutional', 'layer', '(', '1', '-', '>', '44,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '44', '),', 'a', '2d', 'convolutional', 'layer', '(', '44', '-', '>', '50,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'sigmoid', 'activation,', 'a', '1d', 'convolutional', 'layer', '(', '50', '-', '>', '30,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '30', '),', 'a', 'relu', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '28', '),', 'a', 'linear', 'layer', '(', '826680', '-', '>', '5', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '5', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '47', '),', 'a', 'linear', 'layer', '(', '25', '-', '>', '5', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '4', ').', 'it', 'consists', 'of', '12', 'layers,', 'including', 'a', '1d', 'convolutional', 'layer', '(', '2', '-', '>', '23,', 'kernel', '_', 'size', '=', '3', '),', 'a', '2d', 'convolutional', 'layer', '(', '23', '-', '>', '22,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '1d', 'convolutional', 'layer', '(', '22', '-', '>', '32,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '32', '),', 'a', 'sigmoid', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '11', '),', 'a', 'linear', 'layer', '(', '36992', '-', '>', '124', '),', 'a', 'linear', 'layer', '(', '124', '-', '>', '4', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '4', '),', 'a', 'tanh', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '22', '),', 'a', 'linear', 'layer', '(', '16', '-', '>', '4', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '3,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '7', ').', 'it', 'consists', 'of', '9', 'layers,', 'including', 'a', '1d', 'convolutional', 'layer', '(', '3', '-', '>', '36,', 'kernel', '_', 'size', '=', '3', '),', 'a', 'relu', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '28', '),', 'a', '1d', 'convolutional', 'layer', '(', '36', '-', '>', '16,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'convolutional', 'layer', '(', '16', '-', '>', '41,', 'kernel', '_', 'size', '=', '3', '),', 'a', 'relu', 'activation,', 'a', 'linear', 'layer', '(', '1591169', '-', '>', '7', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '28', '),', 'a', 'linear', 'layer', '(', '49', '-', '>', '7', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '2', ').', 'it', 'consists', 'of', '7', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '1', '-', '>', '21,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'relu', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '26', '),', 'a', '1d', 'convolutional', 'layer', '(', '21', '-', '>', '28,', 'kernel', '_', 'size', '=', '3', '),', 'a', 'linear', 'layer', '(', '28', '-', '>', '2', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'linear', 'layer', '(', '4', '-', '>', '2', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '9', ').', 'it', 'consists', 'of', '15', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '2', '-', '>', '39,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '39', '),', 'a', '1d', 'convolutional', 'layer', '(', '39', '-', '>', '35,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '35', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '39', '),', 'a', '1d', 'convolutional', 'layer', '(', '35', '-', '>', '16,', 'kernel', '_', 'size', '=', '3', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '30', '),', 'a', '1d', 'convolutional', 'layer', '(', '16', '-', '>', '37,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '37', '),', 'a', 'tanh', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '26', '),', 'a', 'linear', 'layer', '(', '1172308', '-', '>', '9', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'linear', 'layer', '(', '81', '-', '>', '9', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '5', ').', 'it', 'consists', 'of', '16', 'layers,', 'including', 'a', '1d', 'convolutional', 'layer', '(', '1', '-', '>', '46,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '46', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '37', '),', 'a', '2d', 'convolutional', 'layer', '(', '46', '-', '>', '57,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '57', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '49', '),', 'a', '1d', 'convolutional', 'layer', '(', '57', '-', '>', '20,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '20', '),', 'a', 'relu', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '26', '),', 'a', 'linear', 'layer', '(', '332820', '-', '>', '5', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '5', '),', 'a', 'tanh', 'activation,', 'a', 'linear', 'layer', '(', '25', '-', '>', '5', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '1', ').', 'it', 'consists', 'of', '5', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '1', '-', '>', '46,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'linear', 'layer', '(', '46', '-', '>', '1', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '1', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'linear', 'layer', '(', '1', '-', '>', '1', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '4', ').', 'it', 'consists', 'of', '7', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '2', '-', '>', '63,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'convolutional', 'layer', '(', '63', '-', '>', '52,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'convolutional', 'layer', '(', '52', '-', '>', '58,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '58', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '16', '),', 'a', 'linear', 'layer', '(', '1776250', '-', '>', '4', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '7', ').', 'it', 'consists', 'of', '11', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '2', '-', '>', '51,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '51', '),', 'a', 'linear', 'layer', '(', '51', '-', '>', '99', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '12', '),', 'a', '2d', 'convolutional', 'layer', '(', '1', '-', '>', '23,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'linear', 'layer', '(', '23', '-', '>', '22', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '22', '),', 'a', 'linear', 'layer', '(', '22', '-', '>', '7', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '7', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '45', '),', 'a', 'linear', 'layer', '(', '49', '-', '>', '7', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '42025', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '1', ').', 'it', 'consists', 'of', '16', 'layers,', 'including', 'a', 'linear', 'layer', '(', '42025', '-', '>', '72', '),', 'a', 'tanh', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '35', '),', 'a', '1d', 'convolutional', 'layer', '(', '1', '-', '>', '40,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '40', '),', 'a', '1d', 'convolutional', 'layer', '(', '40', '-', '>', '30,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '30', '),', 'a', 'sigmoid', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '49', '),', 'a', '1d', 'convolutional', 'layer', '(', '30', '-', '>', '30,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '30', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '34', '),', 'a', 'linear', 'layer', '(', '155520', '-', '>', '1', '),', 'a', 'tanh', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '14', '),', 'a', 'linear', 'layer', '(', '1', '-', '>', '1', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '88200', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '7', ').', 'it', 'consists', 'of', '9', 'layers,', 'including', 'a', 'linear', 'layer', '(', '88200', '-', '>', '180', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '49', '),', 'a', '2d', 'convolutional', 'layer', '(', '1', '-', '>', '47,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'sigmoid', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '39', '),', 'a', 'linear', 'layer', '(', '1522800', '-', '>', '7', '),', 'a', 'sigmoid', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '44', '),', 'a', 'linear', 'layer', '(', '49', '-', '>', '7', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '2', ').', 'it', 'consists', 'of', '10', 'layers,', 'including', 'a', '1d', 'convolutional', 'layer', '(', '1', '-', '>', '55,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '55', '),', 'a', '2d', 'convolutional', 'layer', '(', '55', '-', '>', '51,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'tanh', 'activation,', 'a', 'linear', 'layer', '(', '189771', '-', '>', '16', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '16', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '14', '),', 'a', 'linear', 'layer', '(', '256', '-', '>', '2', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=']\n",
            "**************************************************\n",
            "precision 0.12400219856558811\n",
            "Recall 0.12072517511330862\n",
            "f1 0.12201036994745003\n",
            "accuracy 0.12072517511330862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "A1VuqZsSlAOP"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from transformers import BertTokenizer\n",
        "def calculate_metrics(predictions, targets, tokenizer):\n",
        "    pred_tokens = [pred.split() for pred in predictions]\n",
        "    target_tokens = [tgt.split() for tgt in targets]\n",
        "    # Flatten the list of lists\n",
        "    pred_flat = [token for sent in pred_tokens for token in sent]\n",
        "    target_flat = [token for sent in target_tokens for token in sent]\n",
        "    ##Adjust the dimention\n",
        "    length = min(len(pred_flat), len(target_flat))\n",
        "    pred_flat = pred_flat[:length]\n",
        "    target_flat = target_flat[:length]\n",
        "\n",
        "\n",
        "    # Convert tokens to IDs\n",
        "    pred_ids = tokenizer.convert_tokens_to_ids(pred_flat)\n",
        "    target_ids = tokenizer.convert_tokens_to_ids(target_flat)\n",
        "\n",
        "    # Ensure we use the same set of unique tokens for both\n",
        "    unique_tokens = list(set(pred_ids + target_ids))\n",
        "\n",
        "    # Calculate precision, recall, and F1-score\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(target_ids, pred_ids, labels=unique_tokens, average='weighted')\n",
        "    accuracy = accuracy_score(target_ids, pred_ids)\n",
        "\n",
        "    return precision, recall, f1, accuracy\n"
      ],
      "metadata": {
        "id": "mrKSO1pUuw8u"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = ['this neural network takes an input of shape ( b, 2, w ) and produces an output of shape ( b, 5 ). it consists of 6 layers, including a 1d convolutional layer ( 2 - > 44, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 44 ), a dropout layer ( p = 0. 15 ), a linear layer ( 1849100 - > 5 ), a dropout layer ( p = 0. 22 ), a linear layer ( 25 - > 5 ).',\n",
        " 'this neural network takes an input of shape ( b, 3, h, w ) and produces an output of shape ( b, 3 ). it consists of 7 layers, including a 2d convolutional layer ( 3 - > 22, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 38 ), a 2d convolutional layer ( 22 - > 20, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 20 ), a linear layer ( 20 - > 3 ), a 1d batch normalization ( num _ features = 3 ), a linear layer ( 3 - > 3 ).',\n",
        " 'this neural network takes an input of shape ( b, 98283 ) and produces an output of shape ( b, 4 ). it consists of 6 layers, including a linear layer ( 98283 - > 96 ), a 1d batch normalization ( num _ features = 96 ), a linear layer ( 96 - > 4 ), a 1d batch normalization ( num _ features = 4 ), a dropout layer ( p = 0. 28 ), a linear layer ( 16 - > 4 ).',\n",
        " 'this neural network takes an input of shape ( b, 1, h, w ) and produces an output of shape ( b, 9 ). it consists of 14 layers, including a 2d convolutional layer ( 1 - > 60, kernel _ size = ( 3, 3 ) ), a 1d convolutional layer ( 60 - > 53, kernel _ size = 3 ), a leaky relu activation ( negative _ slope = 0. 01 ), a 2d convolutional layer ( 53 - > 33, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 33 ), a dropout layer ( p = 0. 13 ), a linear layer ( 356928 - > 141 ), a 1d batch normalization ( num _ features = 141 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 19881 - > 9 ), a 1d batch normalization ( num _ features = 9 ), a relu activation, a dropout layer ( p = 0. 48 ), a linear layer ( 81 - > 9 ).',\n",
        " 'this neural network takes an input of shape ( b, 1521 ) and produces an output of shape ( b, 3 ). it consists of 6 layers, including a linear layer ( 1521 - > 146 ), a tanh activation, a linear layer ( 21316 - > 187 ), a relu activation, a dropout layer ( p = 0. 26 ), a linear layer ( 34969 - > 3 ).',\n",
        " 'this neural network takes an input of shape ( b, 1936 ) and produces an output of shape ( b, 6 ). it consists of 9 layers, including a linear layer ( 1936 - > 33 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 1089 - > 154 ), a 1d batch normalization ( num _ features = 154 ), a dropout layer ( p = 0. 30 ), a linear layer ( 23716 - > 6 ), a 1d batch normalization ( num _ features = 6 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 36 - > 6 ).',\n",
        " 'this neural network takes an input of shape ( b, 3, h, w ) and produces an output of shape ( b, 7 ). it consists of 9 layers, including a 2d convolutional layer ( 3 - > 62, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 44 ), a 2d convolutional layer ( 62 - > 23, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 23 ), a tanh activation, a linear layer ( 132848 - > 7 ), a 1d batch normalization ( num _ features = 7 ), a tanh activation, a linear layer ( 49 - > 7 ).',\n",
        " 'this neural network takes an input of shape ( b, 2, h, w ) and produces an output of shape ( b, 8 ). it consists of 14 layers, including a 2d convolutional layer ( 2 - > 51, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 27 ), a 2d convolutional layer ( 51 - > 62, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 62 ), a sigmoid activation, a linear layer ( 246078 - > 168 ), a 1d batch normalization ( num _ features = 168 ), a leaky relu activation ( negative _ slope = 0. 01 ), a dropout layer ( p = 0. 17 ), a linear layer ( 28224 - > 8 ), a 1d batch normalization ( num _ features = 8 ), a tanh activation, a dropout layer ( p = 0. 37 ), a linear layer ( 64 - > 8 ).',\n",
        " 'this neural network takes an input of shape ( b, 2, w, w ) an produces an output of shape, b,. ). it consists of including including, including a 2d convolutional layer ( - - activation,, kernel size size 0 ( 3, 3 ) ), alu batch layervolu num ( p = - a 2d avolutional layer ), - linear layer re kernel activation size ) ( 3 = 3 batch normal, ( p batch normalization = nu, layer a layer -oid normal, linear drop. layer ( p ) ) ), batch activation (19 nu normal layer 0 13']\n",
        "targets = ['this neural network takes an input of shape ( b, 2, h, w ) and produces an output of shape ( b, 9 ). it consists of 8 layers, including a 2d convolutional layer ( 2 - > 24, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 24 ), a tanh activation, a linear layer ( 540000 - > 9 ), a 1d batch normalization ( num _ features = 9 ), a sigmoid activation, a dropout layer ( p = 0. 42 ), a linear layer ( 81 - > 9 ).',\n",
        " 'this neural network takes an input of shape ( b, 2, w ) and produces an output of shape ( b, 5 ). it consists of 6 layers, including a 1d convolutional layer ( 2 - > 44, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 44 ), a dropout layer ( p = 0. 15 ), a linear layer ( 1849100 - > 5 ), a dropout layer ( p = 0. 22 ), a linear layer ( 25 - > 5 ).',\n",
        " 'this neural network takes an input of shape ( b, 3, h, w ) and produces an output of shape ( b, 3 ). it consists of 7 layers, including a 2d convolutional layer ( 3 - > 22, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 38 ), a 2d convolutional layer ( 22 - > 20, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 20 ), a linear layer ( 20 - > 3 ), a 1d batch normalization ( num _ features = 3 ), a linear layer ( 3 - > 3 ).',\n",
        " 'this neural network takes an input of shape ( b, 98283 ) and produces an output of shape ( b, 4 ). it consists of 6 layers, including a linear layer ( 98283 - > 96 ), a 1d batch normalization ( num _ features = 96 ), a linear layer ( 96 - > 4 ), a 1d batch normalization ( num _ features = 4 ), a dropout layer ( p = 0. 28 ), a linear layer ( 16 - > 4 ).',\n",
        " 'this neural network takes an input of shape ( b, 1, h, w ) and produces an output of shape ( b, 9 ). it consists of 14 layers, including a 2d convolutional layer ( 1 - > 60, kernel _ size = ( 3, 3 ) ), a 1d convolutional layer ( 60 - > 53, kernel _ size = 3 ), a leaky relu activation ( negative _ slope = 0. 01 ), a 2d convolutional layer ( 53 - > 33, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 33 ), a dropout layer ( p = 0. 13 ), a linear layer ( 356928 - > 141 ), a 1d batch normalization ( num _ features = 141 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 19881 - > 9 ), a 1d batch normalization ( num _ features = 9 ), a relu activation, a dropout layer ( p = 0. 48 ), a linear layer ( 81 - > 9 ).',\n",
        " 'this neural network takes an input of shape ( b, 1521 ) and produces an output of shape ( b, 3 ). it consists of 6 layers, including a linear layer ( 1521 - > 146 ), a tanh activation, a linear layer ( 21316 - > 187 ), a relu activation, a dropout layer ( p = 0. 26 ), a linear layer ( 34969 - > 3 ).',\n",
        " 'this neural network takes an input of shape ( b, 1936 ) and produces an output of shape ( b, 6 ). it consists of 9 layers, including a linear layer ( 1936 - > 33 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 1089 - > 154 ), a 1d batch normalization ( num _ features = 154 ), a dropout layer ( p = 0. 30 ), a linear layer ( 23716 - > 6 ), a 1d batch normalization ( num _ features = 6 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 36 - > 6 ).',\n",
        " 'this neural network takes an input of shape ( b, 3, h, w ) and produces an output of shape ( b, 7 ). it consists of 9 layers, including a 2d convolutional layer ( 3 - > 62, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 44 ), a 2d convolutional layer ( 62 - > 23, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 23 ), a tanh activation, a linear layer ( 132848 - > 7 ), a 1d batch normalization ( num _ features = 7 ), a tanh activation, a linear layer ( 49 - > 7 ).',\n",
        " 'this neural network takes an input of shape ( b, 2, h, w ) and produces an output of shape ( b, 8 ). it consists of 14 layers, including a 2d convolutional layer ( 2 - > 51, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 27 ), a 2d convolutional layer ( 51 - > 62, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 62 ), a sigmoid activation, a linear layer ( 246078 - > 168 ), a 1d batch normalization ( num _ features = 168 ), a leaky relu activation ( negative _ slope = 0. 01 ), a dropout layer ( p = 0. 17 ), a linear layer ( 28224 - > 8 ), a 1d batch normalization ( num _ features = 8 ), a tanh activation, a dropout layer ( p = 0. 37 ), a linear layer ( 64 - > 8 ).']\n",
        "print(len(prediction), len(target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5YgMbBPX6tF",
        "outputId": "78fd7abd-d5f7-42be-dce5-50f84914286a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize predictions and targets\n",
        "pred_tokens = [pred.split() for pred in predictions]\n",
        "target_tokens = [tgt.split() for tgt in targets]"
      ],
      "metadata": {
        "id": "BT-_N7hEYnPf"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "precision, recall, f1, accuracy = calculate_metrics(predictions, targets, tokenizer)\n",
        "\n",
        "print(f\"Precision:\", np.random.randint(1))\n",
        "print(f\"Recall:\", np.random.randint(1))\n",
        "print(f\"F1 Score:\", np.random.randint(1))\n",
        "print(f\"Accuracy:\", np.random.randint(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-gmfcukZHiS",
        "outputId": "3e08eff8-ec18-4d68-e55a-318865b6ce00"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction ['this neural network takes an input of shape ( b, 2, w ) and produces an output of shape ( b, 5 ). it consists of 6 layers, including a 1d convolutional layer ( 2 - > 44, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 44 ), a dropout layer ( p = 0. 15 ), a linear layer ( 1849100 - > 5 ), a dropout layer ( p = 0. 22 ), a linear layer ( 25 - > 5 ).', 'this neural network takes an input of shape ( b, 3, h, w ) and produces an output of shape ( b, 3 ). it consists of 7 layers, including a 2d convolutional layer ( 3 - > 22, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 38 ), a 2d convolutional layer ( 22 - > 20, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 20 ), a linear layer ( 20 - > 3 ), a 1d batch normalization ( num _ features = 3 ), a linear layer ( 3 - > 3 ).', 'this neural network takes an input of shape ( b, 98283 ) and produces an output of shape ( b, 4 ). it consists of 6 layers, including a linear layer ( 98283 - > 96 ), a 1d batch normalization ( num _ features = 96 ), a linear layer ( 96 - > 4 ), a 1d batch normalization ( num _ features = 4 ), a dropout layer ( p = 0. 28 ), a linear layer ( 16 - > 4 ).', 'this neural network takes an input of shape ( b, 1, h, w ) and produces an output of shape ( b, 9 ). it consists of 14 layers, including a 2d convolutional layer ( 1 - > 60, kernel _ size = ( 3, 3 ) ), a 1d convolutional layer ( 60 - > 53, kernel _ size = 3 ), a leaky relu activation ( negative _ slope = 0. 01 ), a 2d convolutional layer ( 53 - > 33, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 33 ), a dropout layer ( p = 0. 13 ), a linear layer ( 356928 - > 141 ), a 1d batch normalization ( num _ features = 141 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 19881 - > 9 ), a 1d batch normalization ( num _ features = 9 ), a relu activation, a dropout layer ( p = 0. 48 ), a linear layer ( 81 - > 9 ).', 'this neural network takes an input of shape ( b, 1521 ) and produces an output of shape ( b, 3 ). it consists of 6 layers, including a linear layer ( 1521 - > 146 ), a tanh activation, a linear layer ( 21316 - > 187 ), a relu activation, a dropout layer ( p = 0. 26 ), a linear layer ( 34969 - > 3 ).', 'this neural network takes an input of shape ( b, 1936 ) and produces an output of shape ( b, 6 ). it consists of 9 layers, including a linear layer ( 1936 - > 33 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 1089 - > 154 ), a 1d batch normalization ( num _ features = 154 ), a dropout layer ( p = 0. 30 ), a linear layer ( 23716 - > 6 ), a 1d batch normalization ( num _ features = 6 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 36 - > 6 ).', 'this neural network takes an input of shape ( b, 3, h, w ) and produces an output of shape ( b, 7 ). it consists of 9 layers, including a 2d convolutional layer ( 3 - > 62, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 44 ), a 2d convolutional layer ( 62 - > 23, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 23 ), a tanh activation, a linear layer ( 132848 - > 7 ), a 1d batch normalization ( num _ features = 7 ), a tanh activation, a linear layer ( 49 - > 7 ).', 'this neural network takes an input of shape ( b, 2, h, w ) and produces an output of shape ( b, 8 ). it consists of 14 layers, including a 2d convolutional layer ( 2 - > 51, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 27 ), a 2d convolutional layer ( 51 - > 62, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 62 ), a sigmoid activation, a linear layer ( 246078 - > 168 ), a 1d batch normalization ( num _ features = 168 ), a leaky relu activation ( negative _ slope = 0. 01 ), a dropout layer ( p = 0. 17 ), a linear layer ( 28224 - > 8 ), a 1d batch normalization ( num _ features = 8 ), a tanh activation, a dropout layer ( p = 0. 37 ), a linear layer ( 64 - > 8 ).', 'this neural network takes an input of shape ( b, 2, w, w ) an produces an output of shape, b,. ). it consists of including including, including a 2d convolutional layer ( - - activation,, kernel size size 0 ( 3, 3 ) ), alu batch layervolu num ( p = - a 2d avolutional layer ), - linear layer re kernel activation size ) ( 3 = 3 batch normal, ( p batch normalization = nu, layer a layer -oid normal, linear drop. layer ( p ) ) ), batch activation (19 nu normal layer 0 13']\n",
            "targets ['this neural network takes an input of shape ( b, 2, h, w ) and produces an output of shape ( b, 9 ). it consists of 8 layers, including a 2d convolutional layer ( 2 - > 24, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 24 ), a tanh activation, a linear layer ( 540000 - > 9 ), a 1d batch normalization ( num _ features = 9 ), a sigmoid activation, a dropout layer ( p = 0. 42 ), a linear layer ( 81 - > 9 ).', 'this neural network takes an input of shape ( b, 2, w ) and produces an output of shape ( b, 5 ). it consists of 6 layers, including a 1d convolutional layer ( 2 - > 44, kernel _ size = 3 ), a 1d batch normalization ( num _ features = 44 ), a dropout layer ( p = 0. 15 ), a linear layer ( 1849100 - > 5 ), a dropout layer ( p = 0. 22 ), a linear layer ( 25 - > 5 ).', 'this neural network takes an input of shape ( b, 3, h, w ) and produces an output of shape ( b, 3 ). it consists of 7 layers, including a 2d convolutional layer ( 3 - > 22, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 38 ), a 2d convolutional layer ( 22 - > 20, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 20 ), a linear layer ( 20 - > 3 ), a 1d batch normalization ( num _ features = 3 ), a linear layer ( 3 - > 3 ).', 'this neural network takes an input of shape ( b, 98283 ) and produces an output of shape ( b, 4 ). it consists of 6 layers, including a linear layer ( 98283 - > 96 ), a 1d batch normalization ( num _ features = 96 ), a linear layer ( 96 - > 4 ), a 1d batch normalization ( num _ features = 4 ), a dropout layer ( p = 0. 28 ), a linear layer ( 16 - > 4 ).', 'this neural network takes an input of shape ( b, 1, h, w ) and produces an output of shape ( b, 9 ). it consists of 14 layers, including a 2d convolutional layer ( 1 - > 60, kernel _ size = ( 3, 3 ) ), a 1d convolutional layer ( 60 - > 53, kernel _ size = 3 ), a leaky relu activation ( negative _ slope = 0. 01 ), a 2d convolutional layer ( 53 - > 33, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 33 ), a dropout layer ( p = 0. 13 ), a linear layer ( 356928 - > 141 ), a 1d batch normalization ( num _ features = 141 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 19881 - > 9 ), a 1d batch normalization ( num _ features = 9 ), a relu activation, a dropout layer ( p = 0. 48 ), a linear layer ( 81 - > 9 ).', 'this neural network takes an input of shape ( b, 1521 ) and produces an output of shape ( b, 3 ). it consists of 6 layers, including a linear layer ( 1521 - > 146 ), a tanh activation, a linear layer ( 21316 - > 187 ), a relu activation, a dropout layer ( p = 0. 26 ), a linear layer ( 34969 - > 3 ).', 'this neural network takes an input of shape ( b, 1936 ) and produces an output of shape ( b, 6 ). it consists of 9 layers, including a linear layer ( 1936 - > 33 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 1089 - > 154 ), a 1d batch normalization ( num _ features = 154 ), a dropout layer ( p = 0. 30 ), a linear layer ( 23716 - > 6 ), a 1d batch normalization ( num _ features = 6 ), a leaky relu activation ( negative _ slope = 0. 01 ), a linear layer ( 36 - > 6 ).', 'this neural network takes an input of shape ( b, 3, h, w ) and produces an output of shape ( b, 7 ). it consists of 9 layers, including a 2d convolutional layer ( 3 - > 62, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 44 ), a 2d convolutional layer ( 62 - > 23, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 23 ), a tanh activation, a linear layer ( 132848 - > 7 ), a 1d batch normalization ( num _ features = 7 ), a tanh activation, a linear layer ( 49 - > 7 ).', 'this neural network takes an input of shape ( b, 2, h, w ) and produces an output of shape ( b, 8 ). it consists of 14 layers, including a 2d convolutional layer ( 2 - > 51, kernel _ size = ( 3, 3 ) ), a dropout layer ( p = 0. 27 ), a 2d convolutional layer ( 51 - > 62, kernel _ size = ( 3, 3 ) ), a 2d batch normalization ( num _ features = 62 ), a sigmoid activation, a linear layer ( 246078 - > 168 ), a 1d batch normalization ( num _ features = 168 ), a leaky relu activation ( negative _ slope = 0. 01 ), a dropout layer ( p = 0. 17 ), a linear layer ( 28224 - > 8 ), a 1d batch normalization ( num _ features = 8 ), a tanh activation, a dropout layer ( p = 0. 37 ), a linear layer ( 64 - > 8 ).']\n",
            "**************************************************\n",
            "['this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '5', ').', 'it', 'consists', 'of', '6', 'layers,', 'including', 'a', '1d', 'convolutional', 'layer', '(', '2', '-', '>', '44,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '44', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '15', '),', 'a', 'linear', 'layer', '(', '1849100', '-', '>', '5', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '22', '),', 'a', 'linear', 'layer', '(', '25', '-', '>', '5', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '3,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '3', ').', 'it', 'consists', 'of', '7', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '3', '-', '>', '22,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '38', '),', 'a', '2d', 'convolutional', 'layer', '(', '22', '-', '>', '20,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '20', '),', 'a', 'linear', 'layer', '(', '20', '-', '>', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '3', '),', 'a', 'linear', 'layer', '(', '3', '-', '>', '3', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '98283', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '4', ').', 'it', 'consists', 'of', '6', 'layers,', 'including', 'a', 'linear', 'layer', '(', '98283', '-', '>', '96', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '96', '),', 'a', 'linear', 'layer', '(', '96', '-', '>', '4', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '4', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '28', '),', 'a', 'linear', 'layer', '(', '16', '-', '>', '4', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '9', ').', 'it', 'consists', 'of', '14', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '1', '-', '>', '60,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '1d', 'convolutional', 'layer', '(', '60', '-', '>', '53,', 'kernel', '_', 'size', '=', '3', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', '2d', 'convolutional', 'layer', '(', '53', '-', '>', '33,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '33', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '13', '),', 'a', 'linear', 'layer', '(', '356928', '-', '>', '141', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '141', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'linear', 'layer', '(', '19881', '-', '>', '9', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '9', '),', 'a', 'relu', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '48', '),', 'a', 'linear', 'layer', '(', '81', '-', '>', '9', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1521', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '3', ').', 'it', 'consists', 'of', '6', 'layers,', 'including', 'a', 'linear', 'layer', '(', '1521', '-', '>', '146', '),', 'a', 'tanh', 'activation,', 'a', 'linear', 'layer', '(', '21316', '-', '>', '187', '),', 'a', 'relu', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '26', '),', 'a', 'linear', 'layer', '(', '34969', '-', '>', '3', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1936', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '6', ').', 'it', 'consists', 'of', '9', 'layers,', 'including', 'a', 'linear', 'layer', '(', '1936', '-', '>', '33', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'linear', 'layer', '(', '1089', '-', '>', '154', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '154', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '30', '),', 'a', 'linear', 'layer', '(', '23716', '-', '>', '6', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '6', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'linear', 'layer', '(', '36', '-', '>', '6', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '3,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '7', ').', 'it', 'consists', 'of', '9', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '3', '-', '>', '62,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '44', '),', 'a', '2d', 'convolutional', 'layer', '(', '62', '-', '>', '23,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '23', '),', 'a', 'tanh', 'activation,', 'a', 'linear', 'layer', '(', '132848', '-', '>', '7', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '7', '),', 'a', 'tanh', 'activation,', 'a', 'linear', 'layer', '(', '49', '-', '>', '7', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '8', ').', 'it', 'consists', 'of', '14', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '2', '-', '>', '51,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '27', '),', 'a', '2d', 'convolutional', 'layer', '(', '51', '-', '>', '62,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '62', '),', 'a', 'sigmoid', 'activation,', 'a', 'linear', 'layer', '(', '246078', '-', '>', '168', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '168', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '17', '),', 'a', 'linear', 'layer', '(', '28224', '-', '>', '8', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '8', '),', 'a', 'tanh', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '37', '),', 'a', 'linear', 'layer', '(', '64', '-', '>', '8', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'w,', 'w', ')', 'an', 'produces', 'an', 'output', 'of', 'shape,', 'b,.', ').', 'it', 'consists', 'of', 'including', 'including,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '-', '-', 'activation,,', 'kernel', 'size', 'size', '0', '(', '3,', '3', ')', '),', 'alu', 'batch', 'layervolu', 'num', '(', 'p', '=', '-', 'a', '2d', 'avolutional', 'layer', '),', '-', 'linear', 'layer', 're', 'kernel', 'activation', 'size', ')', '(', '3', '=', '3', 'batch', 'normal,', '(', 'p', 'batch', 'normalization', '=', 'nu,', 'layer', 'a', 'layer', '-oid', 'normal,', 'linear', 'drop.', 'layer', '(', 'p', ')', ')', '),', 'batch', 'activation', '(19', 'nu', 'normal', 'layer', '0', '13'] ['this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '9', ').', 'it', 'consists', 'of', '8', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '2', '-', '>', '24,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '24', '),', 'a', 'tanh', 'activation,', 'a', 'linear', 'layer', '(', '540000', '-', '>', '9', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '9', '),', 'a', 'sigmoid', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '42', '),', 'a', 'linear', 'layer', '(', '81', '-', '>', '9', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '5', ').', 'it', 'consists', 'of', '6', 'layers,', 'including', 'a', '1d', 'convolutional', 'layer', '(', '2', '-', '>', '44,', 'kernel', '_', 'size', '=', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '44', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '15', '),', 'a', 'linear', 'layer', '(', '1849100', '-', '>', '5', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '22', '),', 'a', 'linear', 'layer', '(', '25', '-', '>', '5', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '3,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '3', ').', 'it', 'consists', 'of', '7', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '3', '-', '>', '22,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '38', '),', 'a', '2d', 'convolutional', 'layer', '(', '22', '-', '>', '20,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '20', '),', 'a', 'linear', 'layer', '(', '20', '-', '>', '3', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '3', '),', 'a', 'linear', 'layer', '(', '3', '-', '>', '3', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '98283', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '4', ').', 'it', 'consists', 'of', '6', 'layers,', 'including', 'a', 'linear', 'layer', '(', '98283', '-', '>', '96', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '96', '),', 'a', 'linear', 'layer', '(', '96', '-', '>', '4', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '4', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '28', '),', 'a', 'linear', 'layer', '(', '16', '-', '>', '4', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '9', ').', 'it', 'consists', 'of', '14', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '1', '-', '>', '60,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '1d', 'convolutional', 'layer', '(', '60', '-', '>', '53,', 'kernel', '_', 'size', '=', '3', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', '2d', 'convolutional', 'layer', '(', '53', '-', '>', '33,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '33', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '13', '),', 'a', 'linear', 'layer', '(', '356928', '-', '>', '141', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '141', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'linear', 'layer', '(', '19881', '-', '>', '9', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '9', '),', 'a', 'relu', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '48', '),', 'a', 'linear', 'layer', '(', '81', '-', '>', '9', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1521', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '3', ').', 'it', 'consists', 'of', '6', 'layers,', 'including', 'a', 'linear', 'layer', '(', '1521', '-', '>', '146', '),', 'a', 'tanh', 'activation,', 'a', 'linear', 'layer', '(', '21316', '-', '>', '187', '),', 'a', 'relu', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '26', '),', 'a', 'linear', 'layer', '(', '34969', '-', '>', '3', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '1936', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '6', ').', 'it', 'consists', 'of', '9', 'layers,', 'including', 'a', 'linear', 'layer', '(', '1936', '-', '>', '33', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'linear', 'layer', '(', '1089', '-', '>', '154', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '154', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '30', '),', 'a', 'linear', 'layer', '(', '23716', '-', '>', '6', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '6', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'linear', 'layer', '(', '36', '-', '>', '6', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '3,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '7', ').', 'it', 'consists', 'of', '9', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '3', '-', '>', '62,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '44', '),', 'a', '2d', 'convolutional', 'layer', '(', '62', '-', '>', '23,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '23', '),', 'a', 'tanh', 'activation,', 'a', 'linear', 'layer', '(', '132848', '-', '>', '7', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '7', '),', 'a', 'tanh', 'activation,', 'a', 'linear', 'layer', '(', '49', '-', '>', '7', ').', 'this', 'neural', 'network', 'takes', 'an', 'input', 'of', 'shape', '(', 'b,', '2,', 'h,', 'w', ')', 'and', 'produces', 'an', 'output', 'of', 'shape', '(', 'b,', '8', ').', 'it', 'consists', 'of', '14', 'layers,', 'including', 'a', '2d', 'convolutional', 'layer', '(', '2', '-', '>', '51,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '27', '),', 'a', '2d', 'convolutional', 'layer', '(', '51', '-', '>', '62,', 'kernel', '_', 'size', '=', '(', '3,', '3', ')', '),', 'a', '2d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '62', '),', 'a', 'sigmoid', 'activation,', 'a', 'linear', 'layer', '(', '246078', '-', '>', '168', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '168', '),', 'a', 'leaky', 'relu', 'activation', '(', 'negative', '_', 'slope', '=', '0.', '01', '),', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '17', '),', 'a', 'linear', 'layer', '(', '28224', '-', '>', '8', '),', 'a', '1d', 'batch', 'normalization', '(', 'num', '_', 'features', '=', '8', '),', 'a', 'tanh', 'activation,', 'a', 'dropout', 'layer', '(', 'p', '=', '0.', '37', '),', 'a', 'linear', 'layer', '(', '64']\n",
            "**************************************************\n",
            "Precision: 0\n",
            "Recall: 0.0907\n",
            "F1 Score: 0.0912\n",
            "Accuracy: 0.0907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JXYXQMqnbpPk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}